---
title: "Leydet_Lab08_Spatial_Data"
author: "David Leydet"
date: "2022-10-18"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: yeti
---

# **Introduction to Simple Features (sf)**

```{r Lab-Setup, message=FALSE}

library(ggplot2)
library(plotly)
library(raster)
library(RColorBrewer)
library(viridis)
library(sf)
library(kableExtra)
library(maps)
library(rgdal)

setwd("~/Desktop/University of Utah PhD /Course Work/Fall 2022 Semester/GEOG6000_Data Analysis/lab08")

```

```{r Data Import}

path_to_data = system.file("shape/nc.shp", package = "sf")

north_carolina = st_read(path_to_data, quiet = TRUE)

#Subsetting North Carolina to include only the CNTY ID, NAME, AREA, and PERIMETER

north_carolina = north_carolina [ , c("CNTY_ID", "NAME", "AREA", "PERIMETER")]

north_carolina

```


```{r Creating Coordinates and Lines}

##Creating two points in space using x,y coordinates:
point_one = st_point(c(0,3))

point_two = st_point(c(5,7))

##Creating a line between two points:

a_line = st_linestring(c(point_one, point_two))

plot(a_line)
     

```

```{r Geometry Typing}

print(point_one)

a_line

##To determine the geometry of your simple feature
st_geometry_type(a_line)

```

```{r Coordinate Reference System}
##The CRS is the most important element of a simple feature - it gives us our spatial coordinates!

##Visit spatialreference.org to determine the EPSG code for the datum you'd like to work with. 

##4326 is the code for WGS84

st_crs(4326)


```

```{r Bounding Box}

##Defines the spatial extent of the data - min/max of x and y

st_bbox(north_carolina)

```

# **Read and Write**


```{r Reading in Spatial Data}
##Reading in data

NY8 = st_read(dsn = "../datafiles/NY_data/NY8_utm18.shp",
              layer = "NY8_utm18",
              drivers = "ESRI Shapefile")


```

```{r Alternative Reading Method}

##Because it is a simple shapefile with the same data source and layer we can use the following syntax
NY8 = st_read("../datafiles/NY_data/NY8_utm18.shp")

```

## **Converting non-spatial data to simple features**

```{r Read in Climate Data}

wna_climate = read.csv("../datafiles/WNAclimate.csv")

head(wna_climate)

```

```{r Convert the Data to a Simple Feature}

##Set as simple feature, using coordinates from the columns LONDD and LATDD, using coordinate system WGS84 (code - 4326)
wna_climate = st_as_sf(wna_climate,
                       coords = c("LONDD", "LATDD"),
                       crs = 4326)

wna_climate

```

```{r Plotting the Spatial Feature - Demo}

myplot = ggplot(wna_climate)

myplot +
  geom_sf(color = "mediumseagreen", alpha = 0.4)
```

```{r Writing Spatial Data, eval = FALSE, message = FALSE}

##Save this to disk as a shape file
st_write(wna_climate, dsn = "../datafiles/wnaclim.shp")

```

# **Coordinate Reference System (CRS) Operations**

**Ensure all of your data is in the same reference system!!**

```{r Check the CRS}

st_crs(NY8)

```

```{r Check the EPSG code}

##Check the EPSG code for your data using $epsg syntax
st_crs(NY8)$epsg

st_crs(wna_climate)$epsg

```


```{r Alternative Method for CRS Check}
##Another way to get the CRS

format(st_crs(NY8))

```

## **Setting the CRS**

```{r Set CRS}

##Note: this should only be used when the simple feature is missing a CRS and you know what it is. It is NOT for re-projecting the sf object to a new coordinate system.

st_crs(wna_climate) = 4326

```


## **Reprojecting CRS**


```{r Reprojecting CRS}
##The st_transform() function allows you to project your sf object to a new CRS. This is particularly useful if you have multiple data sources with different original coordinate systems.

##As a reminder: when you read in spatial data, the first thing you should use is st_crs to check the CRS and st_transform to re-project if necessary.

NY8 = st_transform(NY8, crs = 4326)

##Check to see if it worked - the initial check before the transformation was "NA"
st_crs(NY8)$epsg

```


# **Attribute Operations**

```{r Attribute Class}

oregon_tann = read_sf("../datafiles/oregon/oregontann.shp")

class(oregon_tann)

```


```{r Attribute Table}

oregon_tann %>%
  kbl() %>%
  kable_classic_2() %>%
  scroll_box(width = "500px", height = "200px")

```

```{r Quick Oregon Plot}

##Relook to add boundaries in ggplot

ggplot(oregon_tann) +
  geom_sf(color = "red", alpha = 0.5) +
  xlab("Longitude") +
  ylab("Latitude")


```

## **Select Columns**

```{r Column Selection}
##There are a couple of ways to do this. One way:

oregon_tann2 = subset(oregon_tann, select = c(elevation, tann))

##The geometry column is sticky and stays attached even when you subset
names(oregon_tann2)


```


## **Filter Rows**

```{r Row Selection}
##Subsetting for rows/observation with an elevation over 1000 meters

oregon_tann3 = subset(oregon_tann, subset = elevation > 1000)

##state_bound = map('state', fill = TRUE, plot = FALSE) %>% st_as_sf()

ggplot() +
  geom_sf(data = oregon_tann, aes(color = "red", alpha = 0.9)) +
  geom_sf(data = oregon_tann3, color = "red") +
  #geom_sf(data = state_bound) +
  #coord_sf(xlim = c(-125,-116), ylim = c(42,47)) +
  xlab("Longitude") +
  ylab("Latitude") +
  theme(legend.position = "none")

```

```{r Adding a Column}
##Adding a column
oregon_tann$rando = runif(n = nrow(oregon_tann))

names(oregon_tann)

```

```{r Extracting a Column}
##Extracting a column

elevation = oregon_tann$elevation

elevation[1:10]

```

## **Geometry**

```{r Get Geometry}
##Get the geometry
geometry = oregon_tann$geometry

geometry
```


```{r Drop Geometry}
##Drop Geometry

attributes = st_drop_geometry(oregon_tann)

head(attributes)


```


# **Spatial Operations**

## **Spatial Filter**
```{r Spatial Filter}
##Spatial Filter

#Transform the coordinate system to UTM Zone 18N NAD83
north_carolina = st_transform(north_carolina, crs = 26918)

plot(st_geometry(north_carolina))

```

```{r Spatial Filter Continued}
##Use st_sample to generate random points

##Set seed is used to ensure the random generation is consistent for each iteration
set.seed(1234)

random_pnts = st_sample(north_carolina, size = 500)

##Set as a simple feature (sf)
random_pnts = st_as_sf(random_pnts)

ggplot() +
  geom_sf(data = north_carolina) +
  geom_sf(data = random_pnts, color = "mediumorchid4", alpha = 0.5) +
  theme_light() +
  labs(title = "Random Sample - North Carolina",
       subtitle = "By David, Abby, and Ellie Leydet")


```


```{r Subsetting Spatial Points}

##Subsetting for the County Polygon of Pasquotank
pasq = subset(north_carolina, NAME == "Pasquotank")


##Run the st_filter function to filter the random points by pasq (the district)
filtered_pnts = st_filter(random_pnts, pasq)

myncplot = ggplot() +
  geom_sf(data = north_carolina) +
  theme_light() +
  labs(title = "Random Sample - North Carolina",
       subtitle = "By David, Abby, and Ellie Leydet")

myncplot + geom_sf(data = filtered_pnts, color = "red", alpha = 0.5) +
  labs(caption = "Pasquotank County")
  
  

```

## **Topological Relations**

```{r Disjoint}
##Points outside Pasquotank

out.pasq = st_filter(random_pnts, pasq, .predicate = st_disjoint)

##Editing the plot using the pasq subset to be filled a different color --> see geom_sf(data = pasq, fill = "grey19") line

myncplot + geom_sf(data = out.pasq, color = "mediumorchid4", alpha = 0.5) +
  geom_sf(data = pasq, fill = "grey19") +
  labs(caption = "All points outside of Pasquotank County")

```

```{r Within a Distance Predicate}
##Another useful predicate is st_is_within_distance, which requires that you pass an additional distance (dist) argument to the filter. The dist argument is in units specified by the CRS, in this case meters.

fiftykm.filter = st_filter(random_pnts, pasq,
                           .predicate = st_is_within_distance,
                           dist = 50000)

##Reversed the drawing order so the points appear over the different shaded county

myncplot + geom_sf(data = pasq, fill = "snow1") + 
  geom_sf(data = fiftykm.filter, color = "mediumorchid4", alpha = 0.5) +
  labs(caption = "All points within 50 kilometers of Pasquotank County")


```


# **Geometric Operations**

```{r Centroid, warning = FALSE}
##Centroid

center.of.pasq = st_centroid(pasq)

ggplot() +
  geom_sf(data = pasq) +
  geom_sf(data = center.of.pasq, color = "red", pch = 2) +
  theme_light()

```

```{r Buffer}
##Buffer

pasq.buffer = st_buffer(pasq, dist = 5000)

ggplot() +
  geom_sf(data = pasq.buffer, alpha = 0.8) +
  geom_sf(data = pasq, color = "grey2", fill = "snow1") +
  labs(title = "Pasquotank 5 kilometer Buffer") +
  theme_light()


```

```{r Union}
##Union - merge polygons together into one large feature

nc.boundary = st_union(north_carolina)

ggplot(data = nc.boundary) +geom_sf()


```

```{r Cast}
##To cast a geometry is to change it from one geometry type to another. For example, to convert the boundary of North Carolina to points (the vertices of the polygon)

nc.points = st_cast(nc.boundary, "POINT")

ggplot() + geom_sf(data = nc.points, color = "mediumseagreen", alpha = 0.5 ) + theme_light()


```


```{r Convert to Linestrings}

nc.lines = st_cast(nc.boundary, "MULTILINESTRING")

ggplot() + geom_sf(data = nc.lines)

```


```{r}

nc.lines2 = st_cast(nc.lines, "LINESTRING")

ggplot() + geom_sf(data = nc.lines2)

##If you canâ€™t tell, it was broken into six lines: one for the mainland, and the other five for the ecological (and cultural) disaster known as the Outer Banks. How do we color by polygon?
```


# **Plotting**

```{r ggplot}
##ggplot

NY8v2 <- st_read("../datafiles/NY_data/NY8_utm18.shp")

binghamton = subset(NY8v2, AREANAME == "Binghamton city")

bing.plot = ggplot() +
  theme_bw()

bing.plot + geom_sf(data = binghamton)

```

## **Multiple Geometries**

```{r Multiple Geometries}

## Create a new sf object that has Binghampton and its neighboring polygons
bingies_neighbors = st_filter(NY8v2, binghamton)

## Create a random sample
bing.ran.points = st_sample(bingies_neighbors, size = 25)

## Set the sample as a simple feature (sf)
bing.ran.points = st_as_sf(bing.ran.points)

## REMINDER - THE ORDER THAT THE GEOM_SF ARE WRITTEN IS THE ORDER THEY ARE DRAWN**

bing.plot + geom_sf(data = bingies_neighbors) +
  geom_sf(data = binghamton, fill = "deepskyblue") +
  geom_sf(data = bing.ran.points, color = "brown1", alpha = 0.5, size = 2) 
  

```

## **Plotting Attributes**

```{r Plotting Attributes}

##Attributes names

names(binghamton)

```


```{r Plotting Attributes 2 - Population}

## Plotting a thematic map by population
bing.plot + geom_sf(data = binghamton, aes(fill = POP8))

```


```{r Plotting Attributes 3 - Exposure}

## Plotting a thematic map by exposure
bing.plot + geom_sf(data = binghamton, aes(fill = PEXPOSURE)) +
  scale_fill_viridis(option = "cividis")

```

## **Coordinates**

```{r Coordinate Change}

## 
bing.plot + geom_sf(data = binghamton, aes(fill = PEXPOSURE)) +
  scale_fill_viridis(option = "cividis") +
  coord_sf(datum = 26918)

```


```{r Zoom with Coordinates}

## Make sure the CRS is set appropriately!!!!!
## st_is_valid() check to see if the sf is valid
## st_make_valid() may fix the sf if there are issues

ggplot() + 
  geom_sf(data = binghamton, aes(fill = PEXPOSURE)) +
  scale_fill_viridis(option = "cividis") +
   coord_sf(crs = 4326, xlim = c(-75.91, -75.88), ylim = c(42.10, 42.13)) +
   theme_bw() +
   theme(axis.text.x = element_text(angle = 90))

```


# **Rasters**

```{r Generate a Random Raster}

##Create an empty raster frame
r = raster(nrow = 10, ncol = 10)

## Fill it with random values from 0 to 1

r[] = runif(n=100, min = 0, max = 1)

r
```


```{r Basic R Plot}

plot(r)

```

## **Read and Write Rasters**

```{r Read and Write Rasters}

air_temp = raster("../datafiles/air.mon.ltm.nc")

## Note that we have only **read the first layer (January)**. R will tell you that it loaded the variable called air. To avoid this message you can specify this directly, which is important for files containing multiple variables:##

```

```{r Read and Write 2}

air_temp = raster("../datafiles/air.mon.ltm.nc", varname = "air")

air_temp
```


```{r Write Raster, eval = FALSE}

writeRaster(air_temp, filename = "../datafiles/air_temp.tif")


```


## **Raster CRS**

```{r Raster CRS}

## Set CRS
## Check out the PROJ4 for syntax. Go to the website!!
## "+init=epsg:4326" can be used for rasters so you don't have to write out the full PROJ4 syntax!

crs(air_temp) = "+proj=longlat +ellps=WGS84 +towgs84=0,0,0 +no_defs "

## Check CRS
crs(air_temp)

```


```{r Transform CRS}

weird_crs = crs("+proj=tmerc +lat_0=0 +lon_0=15 +k=0.999923 +x_0=5500000 +y_0=0 +ellps=GRS80 +units=m +no_defs")

air_temp_weird_crs = projectRaster(air_temp, crs = weird_crs)

crs(air_temp_weird_crs)
```


```{r Basic Plotting}

## Plotting

plot(air_temp, main = "NCEP NCAR January LTM Tair")

## Notice how the the the x axis starts at 0 and ends at 360
```

```{r Rotate the Longitude and Color Change}

air_temp = rotate(air_temp)

##Create a color palette with nine colors using color brewer

my.pal = brewer.pal(n = 9, name = "OrRd")

##Add country geometries

countries = st_read("../datafiles/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp", 
                    quiet = TRUE)

## Run these lines together

plot(air_temp,
     main = "NCEP NCAR January LTM Tair",
     col = my.pal)

plot(st_geometry(countries), add = TRUE)

```


## **Summary Statistics**

```{r Summary Stats}

## The function cellStats() can be used to calculate most summary statistics for a raster layer. So to get the mean global temperature (and standard deviation):

cellStats(air_temp, mean)

cellStats(air_temp, sd)

```


## **Subset Rasters**

```{r Subsetting Rasters}
##If we want to use only a subset of the original raster layer, the function crop() will extract only the cells in a given region. This can be defined using another raster object or Spatial* object, or by defining an extent object:


# Extent Method

canada.ext = extent(c(xmin = -143,
                      xmax = -50,
                      ymin = 41,
                      ymax = 84))


canada_air_temp1 = crop(air_temp, canada.ext)


# Spatial Method
canada = subset(countries, NAME == "Canada")

canada_air_temp2 = crop(air_temp, canada)

##Plot both for comparison

par(mfrow = c(1, 2))

plot(canada_air_temp1, 
     main = "NCEP NCAR January LTM Tair",
     sub = "Extent Method",
     col = my.pal)
plot(st_geometry(canada), add = TRUE)


plot(canada_air_temp2, 
     main = "NCEP NCAR January LTM Tair",
     sub = "Spatial Method",
     col = my.pal)
plot(st_geometry(canada), add = TRUE)


```


```{r Masking}

## Note that crop subsets the original raster to the extent of Canadaâ€™s borders, rather than to the borders themselves. This is because rasters are always rectangular. You can â€˜hideâ€™ the values of raster cells outside of a polygon by using the mask function. The raster has to be rectangular, so this does not remove the cells outside the polygon. Rather, it sets their value to NA.

canada_air_temp3 = mask(canada_air_temp2, mask = canada)

plot(canada_air_temp3, 
     main = "NCEP NCAR January LTM Tair", 
     sub = "Masked Version",
     col = my.pal)
plot(st_geometry(canada), add = TRUE)

```

## **Extract Data**

```{r Extracting Data}

## Values can be extracted from individual locations (or sets of locations) using extract(). This can take a set of coordinates in matrix form, or use a Spatial* object. To get the January temperature of Salt Lake City:

##Use long/lat for SLC. Gives value of the cell

extract(air_temp, cbind(-111.9, 40.76))


```


```{r Extracting Data - 2}

##By default this gives you the value of the cell in which the point falls. The value can equally be estimated by bilinear interpolation from the four closest cells with method='bilinear':

extract(air_temp, cbind(-111.9, 40.76), method = "bilinear")


```


```{r Extracting Data - 3}

##Using the wna climate samples locations to subset our data

##Note: character. 'simple' or 'bilinear'. If 'simple' values for the cell a point falls in are returned. If 'bilinear' the returned values are interpolated from the values of the four nearest raster cells.

## 	logical. If df=TRUE, results will be returned as a data.frame. The first column is a sequential ID, the other column(s) are the extracted values

wna.air.temp.df = extract(air_temp,
                          wna_climate,
                          method = "bilinear",
                          df = TRUE)

head(wna.air.temp.df)
```


```{r Extract Data - 4}

## Extracting pixels by polygons

##Create the China Polygon
china = subset(countries, NAME == "China")

china.air.temp.df = extract(air_temp,
                            china,
                            df = TRUE)

head(china.air.temp.df)

```


```{r Extract Data - 5}

##Extracts the temperature data for China
##When this function is used with a set of polygons, the output is in a list, but we can retrieve whatever we want from that list.

##Help on this?

two.countries = rbind(china, canada)

china.tjan = extract(air_temp, two.countries)[[1]]

hist(china.tjan)
```


```{r Extract Data - 6}

##The extract() function also takes an argument fun. This allows you to calculate a summary statistic for each set of pixels that is extracted (i.e. one per polygon). Here, weâ€™ll use this with countries to get an average value of January temperature. We add this back as a new column in the countries object, and then plot it:

countries$Jan_Tmp = extract(air_temp, countries, fun = mean)[,1]

country.temp = ggplot(countries) +
  geom_sf(aes(fill = Jan_Tmp)) +
  labs(fill = "Temperature",
       title = "Mean January Temperature")

ggplotly(country.temp)
```

## **Raster Stacks**

```{r Raster Stacks}

## A useful extension to the basic raster functions is the use of stacks. These are a stack of raster layers which represent different variables, but have the same spatial extent and resolution. 

## Read in the stack
air.temp.stk = stack("../datafiles/air.mon.ltm.nc", varname = "air")

## Rotate the long to -18- to 180
air.temp.stk = rotate(air.temp.stk)

## Change my extent to
myext = extent(c(-130, -60, 25, 50))

## Crop the stack to the extent

air.temp.stk = crop(air.temp.stk, myext)

```


```{r Subset the Stack}

## Subset the first three stacks. Double check what [[]] means. I assume it is the first three stacks as opposed to picking the data out in a matrix

air.temp.substk = air.temp.stk[[1:3]]

air.temp.substk

```


```{r Stack Names}

##Paste names to each stack. month.abb is built in to R
##Potential mismatch between the initial names and the paste? For example X0000.12.30 is December, but now reads as Jan?

names(air.temp.stk) = paste("TAS", month.abb)

names(air.temp.stk)


```


```{r Raster Pull by Name}

#Raster stack pull by name

## Method 1

air.temp.jan = air.temp.stk$TAS.Jan

## Method 2

air.temp.jan2 = air.temp.stk[["TAS.Jan"]]

air.temp.jan

```

### **Plotting Stacks**

```{r Plotting Stacks}

## Plotting stacks. zlim syntax sets the same scale for each stack

plot(air.temp.stk,
     col = my.pal,
     zlim = c(-35, 35))



```


```{r Adding Additional Spatial Data}

## Turn countries into spatial data to add to plot
## addfun Function to add additional items such as points or polygons to the plot (map). Typically containing statements like "points(xy); plot(polygons, add=TRUE)". This is particularly useful to add something to each map when plotting a multi-layer Raster* object.

addBorder = function() {plot(as_Spatial(countries), add = TRUE)}

plot(air.temp.stk,
     col = my.pal,
     zlim = c(-35, 35),
     addfun = addBorder)

```

### **cellStats Function**

```{r cellStats Function}

#The cellStats() function now returns the mean (or other statistic) for all layers, allowing a quick look at the seasonal cycle of average air temperature.

tavg = cellStats(air.temp.stk, mean)

plot(1:12, tavg,
     type = "l",
     col = "red",
     xlab = "Month",
     ylab = "Average Temperature (Celsius)")
```


```{r Extract a Single Location}
## Extract a single location
## Colorado Springs 38.8339Â° N, 104.8214Â° W

cos.tavg = extract(air.temp.stk, cbind(-104.82, 38.83), method = "bilinear")

plot(1:12, cos.tavg,
     type = "l",
     col = "red",
     xlab = "Month",
     ylab = "Average Temperature (Celsius)",
     main = "Average Colorado Springs Temperature")

```


